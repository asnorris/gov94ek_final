---
title: "Untitled"
author: "Alexandra Norris"
date: "12/13/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(haven)
library(fuzzyjoin)
library(lubridate)
library(usmap)
```

```{r}

# # load in data from regions and then merge it together
# 
# central_atlantic <- read_csv("eia_data/Weekly_Central_Atlantic_(PADD_1B)_All_Grades_All_Formulations_Retail_Gasoline_Prices.csv") %>%
#   mutate(region = "central_atlantic")
# 
# east_coast <- read_csv("eia_data/Weekly_East_Coast_All_Grades_All_Formulations_Retail_Gasoline_Prices.csv") %>%
#   mutate(region = "east_coast")
# 
# gulf_coast <- read_csv("eia_data/Weekly_Gulf_Coast_All_Grades_All_Formulations_Retail_Gasoline_Prices.csv") %>%
#   mutate(region = "gulf_coast")
# 
# low_atlantic <- read_csv("eia_data/Weekly_Lower_Atlantic_(PADD_1C)_All_Grades_All_Formulations_Retail_Gasoline_Prices.csv") %>%
#   mutate(region = "low_atlantic")
# 
# midwest <- read_csv("eia_data/Weekly_Midwest_All_Grades_All_Formulations_Retail_Gasoline_Prices.csv") %>%
#   mutate(region = "midwest")
# 
# rockies <- read_csv("eia_data/Weekly_Rocky_Mountain_All_Grades_All_Formulations_Retail_Gasoline_Prices.csv") %>%
#   mutate(region = "rocky_mountains") 
# 
# total_us <- read_csv("eia_data/Weekly_U.S._All_Grades_All_Formulations_Retail_Gasoline_Prices.csv") %>%
#   mutate(region = "usa") 
# 
# wc_no_cal <- read_csv("eia_data/Weekly_West_Coast_(PADD_5)_Except_California_All_Grades_All_Formulations_Retail_Gasoline_Prices.csv") %>%
#   mutate(region = "wc_no_cal")
# 
# wc <- read_csv("eia_data/Weekly_West_Coast_All_Grades_All_Formulations_Retail_Gasoline_Prices.csv") %>%
#   mutate(region = "west_coast")
# 
# # merge together data and change "/" to "-" so I can make it a date
# 
# gas <- rbind(central_atlantic, east_coast, gulf_coast, low_atlantic, midwest, rockies, total_us, wc_no_cal, wc)
# 
# # add states 

```

```{r}

# read in state gas price data

ca <- read_csv("eia_data_states/Weekly_California_All_Grades_All_Formulations_Retail_Gasoline_Prices.csv") %>%
   mutate(state = "CA")

co <- read_csv("eia_data_states/Weekly_Colorado_All_Grades_All_Formulations_Retail_Gasoline_Prices.csv") %>%
   mutate(state = "CO")

fl <- read_csv("eia_data_states/Weekly_Florida_All_Grades_All_Formulations_Retail_Gasoline_Prices.csv") %>%
   mutate(state = "FL")

ma <- read_csv("eia_data_states/Weekly_Massachusetts_All_Grades_All_Formulations_Retail_Gasoline_Prices.csv") %>%
   mutate(state = "MA")

mn <- read_csv("eia_data_states/Weekly_Minnesota_All_Grades_All_Formulations_Retail_Gasoline_Prices.csv") %>%
   mutate(state = "MN")

ny <- read_csv("eia_data_states/Weekly_New_York_All_Grades_All_Formulations_Retail_Gasoline_Prices.csv") %>%
   mutate(state = "NY")

oh <- read_csv("eia_data_states/Weekly_Ohio_All_Grades_All_Formulations_Retail_Gasoline_Prices.csv") %>%
   mutate(state = "OH")

tx <- read_csv("eia_data_states/Weekly_Texas_All_Grades_All_Formulations_Retail_Gasoline_Prices.csv") %>%
   mutate(state = "TX")

wa <- read_csv("eia_data_states/Weekly_Washington_All_Grades_All_Formulations_Retail_Gasoline_Prices.csv") %>%
   mutate(state = "WA")

# merge together states
gas <- rbind(ca,co,fl,ma,mn,ny,oh,tx,wa) %>%
  rename(date = week)

```

```{r}

# download FEMA data that denotes disasters and filter for relevant data
# have to do ohio seperagely because gas data starts in 2003 not 2000 like the rest - makes it so the nearest merge works better

ohio <- read_csv("DisasterDeclarationsSummaries.csv") %>%
  filter(state == "OH") %>%
  mutate(date = as.Date(declarationDate, format = "%Y-%m-%d")) %>%
  filter(date >= '2003-01-01') %>%
  select(disasterNumber, state, declarationDate, date, incidentType)

rest <- read_csv("DisasterDeclarationsSummaries.csv") %>%
  filter(state %in% c("CA","CO","FL","MA","MN","NY","TX","WA")) %>%
  mutate(date = as.Date(declarationDate, format = "%Y-%m-%d")) %>%
  filter(date >= '2000-01-01') %>%
  select(disasterNumber, state, declarationDate, date, incidentType)

disaster <- rbind(rest, ohio)

```

```{r, message=FALSE}

# used function from internet to do nearest neighbor joining

match_by_group_date <- function(df1, df2, grp, datecol) {
  
  grp1 <- df1 %>% pull({{grp}}) %>% unique()
  grp2 <- df2 %>% pull({{grp}}) %>% unique()
  
  li <-
  lapply(intersect(grp1, grp2), function(tt) {
    d1 <- filter(df1, {{grp}}== tt)
    d2 <- filter(df2, {{grp}}==tt) %>% mutate(indices = 1:n())
    d2_date <- d2 %>% pull({{datecol}}) %>% as.POSIXct()
    print(d2_date)
    d1 <- mutate(d1, indices = map_dbl({{datecol}}, function(d) which.min(abs(d2_date - as.POSIXct(d)))))
    
    left_join(d1,d2, by=c(quo_name(enquo(grp)), "indices"))
  })
  
  # bind rows
  return(bind_rows(li))
}


joined_data <- match_by_group_date(gas, disaster, state, date)

```

```{r warning=FALSE}
# rename columns so that I know what's what with the dates

data <- joined_data %>%
  rename(gas_date = date.x) %>%
  rename(disaster_date = date.y) %>%
  filter(gas_date < '2021-10-26') %>%
  group_by(disasterNumber) %>%
  # mutate(pre = ifelse(gas_date < disaster_date,1, ifelse(gas_date==disaster_date,1, 0))) %>%
  mutate(dist = gas_date - disaster_date) %>%
  mutate(pre = ifelse(dist <= 3,1,0)) %>%
  filter(between(dist, -11, 17)) %>%
  mutate(time = ifelse(pre == 1, "pre_dis", "post_dis")) %>%
  group_by(state, disasterNumber, pre) %>%
  mutate(avj_price = mean(price)) %>%
  ungroup() %>%
  select(state, disasterNumber, avj_price, time, incidentType) %>%
  distinct() %>%
  group_by(state, disasterNumber) %>%
  pivot_wider(names_from = time, values_from = avj_price) %>%
  na.omit()

```




```{r}
# download price gouging law data. From: https://www.findlaw.com/consumer/consumer-transactions/price-gouging-laws-by-state.html
# also replace na values with 0 for threshold exists so that regression works

gouge <- read_csv("price_gouguing_laws - Sheet1.csv") %>%
  select(state, law_exists, threshold_exists, threshold)

sum(gouge$threshold_exists, na.rm = TRUE)
```


```{r}

# create a map that displays the variation in laws across the country

library("imputeTS")
map_gouge <- gouge %>%
  mutate(value = as.factor(threshold_exists + law_exists))
# 
map_gouge <- na.replace(map_gouge, 0)

map <- plot_usmap(data = map_gouge, values = "value", color = "black") + 
  theme(legend.position = "right") +
  scale_fill_manual(values = c("firebrick","steelblue"), labels = c("Vague Law","Law with Threshold","No Law"), name = "Type of Price Gouging Law")
    
ggsave("final_paper/law_map.pdf", height = 3.5, width = 7)
map
```
```{r}

# merge together law data with gas/disaster data

data <- left_join(data, gouge) %>%
  mutate(price_change = post_dis - pre_dis)

```

```{r}

# find most prevalent incidents
data %>%
  group_by(incidentType) %>%
  mutate(count = n()) %>%
  select(incidentType, count) %>%
  distinct() %>%
  arrange(desc(count))
# top 5 include fire, severe storms, hurricanes, flood, and snow

# attempt at a regression

mod1 <- lm(price_change ~ law_exists, data = data)

mod2 <- lm(price_change ~ threshold_exists, data = data)

mod3 <- lm(price_change ~ law_exists + incidentType, data = data)

cat(stargazer::stargazer(mod1,mod2,mod3, ci = TRUE, omit = c("incidentTypeCoastal Storm", "incidentTypeDam/Levee Break", "incidentTypeEarthquake", "incidentTypeFreezing",
                                                                           "incidentTypeMud/Landslide", "incidentTypeOther", "incidentTypeSevere Ice Storm", "incidentTypeTornado",
                                                                           "incidentTypeTsunami"),
                     covariate.labels = c("Law Exists","Gouging Threshold Exists","Fire","Flood","Hurricane","Severe Storm(s)","Snow", "Constant"), dep.var.labels = "Post-Disaster Price Change"),
                     file="final_paper/tab2.tex", sep="\n")

# limitation - does not observe the trends before

```

```{r}


require(gt)

num <- data %>%
  group_by(law_exists, threshold_exists) %>%
  mutate(avj_change = mean(price_change)) %>%
  select(law_exists, threshold_exists, avj_change) %>%
  distinct() %>%
  ungroup() %>%
  select(avj_change)

type <- c("Law with Threshold","No Law","Law Without Threshold (vague)")

dif_mean <- data_frame(type, num)

# create table
dif_mean %>%
  gt() %>%
  cols_label(type = "", avj_change = "Average Price Change") %>%
  gtsave("final_paper/tab1.tex")


```

```{r}

# use different data to do the dif in dif analysis

dif_dat <- joined_data %>%
  rename(gas_date = date.x) %>%
  rename(disaster_date = date.y) %>%
  filter(gas_date < '2021-10-26') %>%
  group_by(disasterNumber) %>%
  mutate(pre = ifelse(gas_date < disaster_date,1, ifelse(gas_date==disaster_date,1, 0))) %>%
  mutate(dist = gas_date - disaster_date) %>%
  # mutate(adj_dist = dist - 6)
  filter(between(dist, -21, 21)) %>%
  mutate(distance = as.numeric(dist)) %>%
  mutate(time = ifelse(pre == 1, "pre_dis", "post_dis"))

dif_dat <- merge(dif_dat, gouge)

dif_dat %>%
  # group_by(law_exists, )
  mutate(law_exists = as.factor(law_exists)) %>%
  ggplot(aes(x = distance, y = price, group = law_exists, color = law_exists)) +
  # geom_point() +
  stat_smooth(method = "loess", formula = y ~ x, size = 1) +
  theme_classic() +
  geom_vline(xintercept=c(0,7), linetype=c("dashed","dotted"), color = c("black", "red")) +
  labs(x = "Distance (days) From Disaster", y = "Gasoline Price", color = "") +
  scale_color_manual(values = c("firebrick","steelblue"), labels = c("No Law", "Law Prohibiting Gouging"))

ggsave("final_paper/fig2.pdf",  height =3.5, width = 7)
```


